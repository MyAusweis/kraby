# References

<!-- Generate with
bibtex2html -dl -nobibsource -noheader -nofooter -noabstract -nokeywords -d -nodoc -s ieeetr hexapod.bib
-->

<dl>

<dt>
[<a name="coumans2020">1</a>]
</dt>
<dd>
E.&nbsp;Coumans and Y.&nbsp;Bai, &ldquo;Pybullet, a python module for physics simulation for
  games, robotics and machine learning,&rdquo; 2016-2020.
[&nbsp;<a href="http://pybullet.org">http</a>&nbsp;]

</dd>


<dt>
[<a name="brockman2016openai">2</a>]
</dt>
<dd>
G.&nbsp;Brockman, V.&nbsp;Cheung, L.&nbsp;Pettersson, J.&nbsp;Schneider, J.&nbsp;Schulman, J.&nbsp;Tang, and
  W.&nbsp;Zaremba, &ldquo;Openai gym,&rdquo; 2016.
[&nbsp;<a href="http://arxiv.org/abs/1606.01540">http</a>&nbsp;]

</dd>


<dt>
[<a name="henderson2017reinforcement">3</a>]
</dt>
<dd>
P.&nbsp;Henderson, R.&nbsp;Islam, P.&nbsp;Bachman, J.&nbsp;Pineau, D.&nbsp;Precup, and D.&nbsp;Meger, &ldquo;Deep
  reinforcement learning that matters,&rdquo; 2017.
[&nbsp;<a href="http://arxiv.org/abs/1709.06560">http</a>&nbsp;]

</dd>


<dt>
[<a name="schulman2017ppo">4</a>]
</dt>
<dd>
J.&nbsp;Schulman, F.&nbsp;Wolski, P.&nbsp;Dhariwal, A.&nbsp;Radford, and O.&nbsp;Klimov, &ldquo;Proximal
  policy optimization algorithms.,&rdquo; <em>CoRR</em>, 2017.
[&nbsp;<a href="http://arxiv.org/abs/1707.06347">http</a>&nbsp;]

</dd>


<dt>
[<a name="SpinningUp2018">5</a>]
</dt>
<dd>
J.&nbsp;Achiam, &ldquo;Spinning up in deep reinforcement learning,&rdquo; 2018.
[&nbsp;<a href="https://spinningup.openai.com">http</a>&nbsp;]

</dd>
</dl>