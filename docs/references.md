# References

<!-- Generate with
bibtex2html -dl -nobibsource -noheader -nofooter -noabstract -nokeywords -d -nodoc -s apalike docs/bibliography.bib
-->

<dl>

<dt>
[<a name="sutton1998">Sutton and Barto, 1998</a>]
</dt>
<dd>
Sutton, R.&nbsp;S. and Barto, A.&nbsp;G. (1998).
 <em>Reinforcement Learning: An Introduction</em>.
 The MIT Press.

</dd>


<dt>
[<a name="madgwick2010efficient">Madgwick et&nbsp;al., 2010</a>]
</dt>
<dd>
Madgwick, S., Vaidyanathan, R., and Harrison, A. (2010).
 An efficient orientation filter for inertial measurement units (imus)
  and magnetic angular rate and gravity (marg) sensor arrays.
 Technical report, Department of Mechanical Engineering.
[&nbsp;<a href="http://www.scribd.com/doc/29754518/A-Efficient-Orientation-Filter-for-IMUs-and-MARG-Sensor-Arrays">http</a>&nbsp;]

</dd>


<dt>
[<a name="kingma2014method">Kingma and Ba, 2014</a>]
</dt>
<dd>
Kingma, D.&nbsp;P. and Ba, J. (2014).
 Adam: A method for stochastic optimization.
[&nbsp;<a href="https://arxiv.org/abs/1412.6980">http</a>&nbsp;]

</dd>


<dt>
[<a name="schulman2015high">Schulman et&nbsp;al., 2015</a>]
</dt>
<dd>
Schulman, J., Moritz, P., Levine, S., Jordan, M., and Abbeel, P. (2015).
 High-dimensional continuous control using generalized advantage
  estimation.
[&nbsp;<a href="https://arxiv.org/abs/1506.02438">http</a>&nbsp;]

</dd>


<dt>
[<a name="coumans2020">Coumans and Bai, 2016</a>]
</dt>
<dd>
Coumans, E. and Bai, Y. (2016).
 Pybullet, a python module for physics simulation for games, robotics
  and machine learning.
[&nbsp;<a href="http://pybullet.org">http</a>&nbsp;]

</dd>


<dt>
[<a name="brockman2016openai">Brockman et&nbsp;al., 2016</a>]
</dt>
<dd>
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W. (2016).
 Openai gym.
[&nbsp;<a href="https://arxiv.org/abs/1606.01540">http</a>&nbsp;]

</dd>


<dt>
[<a name="DuanCHSA16">Duan et&nbsp;al., 2016</a>]
</dt>
<dd>
Duan, Y., Chen, X., Houthooft, R., Schulman, J., and Abbeel, P. (2016).
 Benchmarking deep reinforcement learning for continuous control.
 <em>CoRR</em>.
[&nbsp;<a href="https://arxiv.org/abs/1604.06778">http</a>&nbsp;]

</dd>


<dt>
[<a name="henderson2017">Henderson et&nbsp;al., 2017</a>]
</dt>
<dd>
Henderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D., and Meger, D.
  (2017).
 Deep reinforcement learning that matters.
[&nbsp;<a href="https://arxiv.org/abs/1709.06560">http</a>&nbsp;]

</dd>


<dt>
[<a name="schulman2017ppo">Schulman et&nbsp;al., 2017</a>]
</dt>
<dd>
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O. (2017).
 Proximal policy optimization algorithms.
 <em>CoRR</em>.
[&nbsp;<a href="https://arxiv.org/abs/1707.06347">http</a>&nbsp;]

</dd>


<dt>
[<a name="SpinningUp2018">Achiam, 2018</a>]
</dt>
<dd>
Achiam, J. (2018).
 Spinning up in deep reinforcement learning.
[&nbsp;<a href="https://spinningup.openai.com">http</a>&nbsp;]

</dd>


<dt>
[<a name="tan2018sim">Tan et&nbsp;al., 2018</a>]
</dt>
<dd>
Tan, J., Zhang, T., Coumans, E., Iscen, A., Bai, Y., Hafner, D., Bohez, S., and
  Vanhoucke, V. (2018).
 Sim-to-real: Learning agile locomotion for quadruped robots.
[&nbsp;<a href="https://arxiv.org/abs/1804.10332">http</a>&nbsp;]

</dd>


<dt>
[<a name="stable-baselines">Hill et&nbsp;al., 2018</a>]
</dt>
<dd>
Hill, A., Raffin, A., Ernestus, M., Gleave, A., Kanervisto, A., Traore, R.,
  Dhariwal, P., Hesse, C., Klimov, O., Nichol, A., Plappert, M., Radford, A.,
  Schulman, J., Sidor, S., and Wu, Y. (2018).
 Stable baselines.
[&nbsp;<a href="https://github.com/hill-a/stable-baselines">http</a>&nbsp;]

</dd>


<dt>
[<a name="rl-zoo">Raffin, 2018</a>]
</dt>
<dd>
Raffin, A. (2018).
 Rl baselines zoo.
[&nbsp;<a href="https://github.com/araffin/rl-baselines-zoo">http</a>&nbsp;]

</dd>


<dt>
[<a name="journals/corr/abs-1907-10902">Akiba et&nbsp;al., 2019</a>]
</dt>
<dd>
Akiba, T., Sano, S., Yanase, T., Ohta, T., and Koyama, M. (2019).
 Optuna: A next-generation hyperparameter optimization framework.
 <em>CoRR</em>.
[&nbsp;<a href="http://arxiv.org/abs/1907.10902">http</a>&nbsp;]

</dd>
</dl>
